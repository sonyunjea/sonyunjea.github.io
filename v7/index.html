<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale-1.0">
    <title>영상신호 처리 핵심 개념 탐색기</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <!-- Chosen Palette: Slate & Indigo -->
    <!-- Application Structure Plan: The SPA is designed as an interactive learning hub, moving away from a linear Q&A. A top-level navigation grid with thematic categories (Basics, Perceptrons, Deep Learning Core, Techniques) allows users to explore concepts non-linearly. Clicking a category dynamically loads detailed explanations and topic-specific interactive visualizations (e.g., charts for logic gates, activation functions) into a central content area. This structure promotes user-driven learning and better illustrates complex relationships between concepts compared to static text. -->
    <!-- Visualization & Content Choices: 
        - Logic Gates -> Goal: Compare/Inform -> Viz: Interactive Scatter Plot (Chart.js) -> Interaction: Buttons to switch datasets (AND/OR/XOR) & see decision boundaries -> Justification: Visually proves the non-linear nature of XOR, which is a core concept.
        - Activation Functions -> Goal: Compare -> Viz: Line Chart (Chart.js) -> Interaction: Buttons to toggle display of Sigmoid, Tanh, Identity -> Justification: Directly compares the output ranges and shapes, making their differences intuitive.
        - CNN Process -> Goal: Organize -> Viz: HTML/CSS Flowchart Diagram -> Interaction: Clickable stages to reveal text -> Justification: Simplifies a complex process into a digestible, step-by-step visual flow.
        - Other Concepts -> Goal: Inform -> Viz: Styled text blocks and simple HTML/CSS diagrams (e.g., network layers) -> Justification: Provides clear, readable explanations for foundational knowledge. -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Pretendard', sans-serif;
            scroll-behavior: smooth;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 500px;
            margin-left: auto;
            margin-right: auto;
            height: 300px;
            max-height: 40vh;
        }
        .nav-card {
            transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
        }
        .nav-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
        }
        .content-fade-in {
            animation: fadeIn 0.5s ease-in-out;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        code {
            background-color: #eef2ff;
            color: #4338ca;
            padding: 0.2rem 0.4rem;
            border-radius: 0.25rem;
            font-family: monospace;
            font-size: 0.9em;
        }
    </style>
</head>
<body class="bg-slate-50 text-slate-800">

    <div class="container mx-auto px-4 py-8 md:py-12">
        <header class="text-center mb-10">
            <h1 class="text-4xl md:text-5xl font-bold text-slate-900">영상신호 처리 핵심 개념 탐색기</h1>
            <p class="mt-4 text-lg text-slate-600">딥러닝과 신경망의 기본 원리를 대화형으로 학습해보세요.</p>
        </header>

        <nav id="navigation" class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-4 gap-6 mb-12">
            <div data-topic="basics" class="nav-card cursor-pointer bg-white p-6 rounded-xl shadow-md border border-slate-200">
                <h3 class="text-xl font-semibold text-indigo-600">기초 개념</h3>
                <p class="text-slate-500 mt-2">신경망, 데이터 셋 등 기본 용어를 알아봅니다.</p>
            </div>
            <div data-topic="perceptrons" class="nav-card cursor-pointer bg-white p-6 rounded-xl shadow-md border border-slate-200">
                <h3 class="text-xl font-semibold text-indigo-600">퍼셉트론의 발전</h3>
                <p class="text-slate-500 mt-2">단층, 다층 퍼셉트론과 XOR 문제를 탐구합니다.</p>
            </div>
            <div data-topic="deeplearning" class="nav-card cursor-pointer bg-white p-6 rounded-xl shadow-md border border-slate-200">
                <h3 class="text-xl font-semibold text-indigo-600">딥러닝 핵심</h3>
                <p class="text-slate-500 mt-2">CNN의 구조와 이미지 처리 과정을 학습합니다.</p>
            </div>
            <div data-topic="techniques" class="nav-card cursor-pointer bg-white p-6 rounded-xl shadow-md border border-slate-200">
                <h3 class="text-xl font-semibold text-indigo-600">학습 기법과 함수</h3>
                <p class="text-slate-500 mt-2">학습률, 활성화 함수, 전이 학습을 이해합니다.</p>
            </div>
        </nav>

        <main id="content-display" class="bg-white p-6 sm:p-8 rounded-2xl shadow-lg min-h-[400px]">
             <div class="text-center py-20">
                <h2 class="text-2xl font-semibold text-slate-700">궁금한 주제를 선택하여 학습을 시작하세요.</h2>
                <p class="text-slate-500 mt-2">위의 네 가지 주제 카드 중 하나를 클릭하면 여기에 설명이 표시됩니다.</p>
            </div>
        </main>
    </div>

    <script>
        const contentData = {
            basics: `
                <h2 class="text-3xl font-bold mb-6 text-slate-900 border-b-2 border-indigo-200 pb-2">기초 개념</h2>
                <p class="mb-8 text-slate-600">인공 신경망과 머신러닝의 가장 기본적인 구성 요소들을 알아봅니다. 이 개념들은 더 복잡한 딥러닝 모델을 이해하기 위한 첫걸음입니다.</p>
                <div class="space-y-8">
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">신경망 (Neural Network)</h3>
                        <p>인공 신경망은 인간의 뇌가 작동하는 방식을 모방하여 만든 계산 모델입니다. 데이터가 입력되는 <strong>입력층</strong>, 실제 연산이 대부분 이루어지는 하나 이상의 <strong>은닉층</strong>, 그리고 최종 결과가 출력되는 <strong>출력층</strong>으로 구성됩니다. 생물학적 뉴런처럼 신호를 받아 처리하고 다음 뉴런으로 전달하는 원리를 수학적으로 구현한 것입니다.</p>
                    </div>
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">데이터 셋 (Dataset)</h3>
                        <p>머신러닝 모델을 학습시키고 평가하기 위해 사용되는 데이터의 집합입니다. 일반적으로 <strong>훈련(Training)</strong>, <strong>검증(Validation)</strong>, <strong>테스트(Test)</strong> 데이터 셋으로 분리하여 사용합니다.<br>
                        - <strong>훈련 셋:</strong> 모델의 가중치를 학습시키기 위해 사용합니다.<br>
                        - <strong>검증 셋:</strong> 학습 중인 모델의 성능을 확인하고 하이퍼파라미터를 조정합니다.<br>
                        - <strong>테스트 셋:</strong> 학습이 완료된 모델의 최종 성능을 객관적으로 평가합니다.</p>
                    </div>
                     <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">신경회로망 (Neural Circuit Network)</h3>
                        <p>신경회로망(인공 신경망)은 수많은 뉴런들이 서로 연결되어 신호를 주고받으며 학습하는 뇌 구조에서 영감을 받았습니다. 정보는 입력층에서 시작하여, 각 층의 노드(뉴런)들이 가중치가 적용된 신호를 계산하고 활성화 함수를 통해 다음 층으로 전달하는 과정을 거쳐 최종적으로 출력층에서 결과로 나타납니다.</p>
                    </div>
                </div>
            `,
            perceptrons: `
                <h2 class="text-3xl font-bold mb-6 text-slate-900 border-b-2 border-indigo-200 pb-2">퍼셉트론의 발전과 XOR 문제</h2>
                <p class="mb-8 text-slate-600">가장 단순한 신경망인 퍼셉트론부터 시작하여, 그 한계와 이를 극복하기 위한 다층 퍼셉트론의 등장까지 알아봅니다. 특히 XOR 문제는 신경망 연구의 중요한 전환점이 되었습니다.</p>
                <div class="space-y-8">
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">단층 vs 다층 퍼셉트론</h3>
                        <p><strong>단층 퍼셉트론(Single-Layer Perceptron)</strong>은 입력층과 출력층만으로 구성된 선형 분류기입니다. 이 때문에 하나의 직선으로 데이터를 나눌 수 있는 AND, OR 같은 문제는 해결할 수 있지만, 직선 하나로는 나눌 수 없는 <strong>XOR 같은 비선형 문제는 해결하지 못합니다.</strong><br>
                        <strong>다층 퍼셉트론(Multi-Layer Perceptron)</strong>은 입력층과 출력층 사이에 하나 이상의 은닉층을 추가한 구조입니다. 이 은닉층 덕분에 비선형적인 결정 경계를 만들 수 있어 XOR 문제를 비롯한 복잡한 문제들을 해결할 수 있습니다.</p>
                    </div>
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">논리 게이트 시각화</h3>
                        <p>아래 차트에서 버튼을 클릭하여 각 논리 게이트의 데이터 분포를 확인하고, 왜 단층 퍼셉트론이 XOR 문제를 해결할 수 없는지 직접 확인해보세요.</p>
                        <div class="chart-container"><canvas id="logicGateChart"></canvas></div>
                        <div class="flex justify-center space-x-2 mt-4">
                            <button onclick="updateLogicChart('AND')" class="bg-indigo-500 text-white px-4 py-2 rounded-lg hover:bg-indigo-600 transition">AND</button>
                            <button onclick="updateLogicChart('OR')" class="bg-indigo-500 text-white px-4 py-2 rounded-lg hover:bg-indigo-600 transition">OR</button>
                            <button onclick="updateLogicChart('XOR')" class="bg-indigo-500 text-white px-4 py-2 rounded-lg hover:bg-indigo-600 transition">XOR</button>
                        </div>
                    </div>
                </div>
            `,
            deeplearning: `
                <h2 class="text-3xl font-bold mb-6 text-slate-900 border-b-2 border-indigo-200 pb-2">딥러닝 핵심</h2>
                <p class="mb-8 text-slate-600">여러 개의 은닉층을 가진 심층 신경망, 즉 딥러닝의 기본 구조와 영상 처리에 특화된 CNN 모델의 작동 원리를 살펴봅니다.</p>
                 <div class="space-y-8">
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">딥러닝(Deep Learning)의 구조</h3>
                        <p>딥러닝은 여러 개의 은닉층을 가진 인공 신경망을 사용해 데이터로부터 복잡한 특징을 스스로 학습하는 기술입니다. 모델은 크게 두 부분으로 나뉩니다.<br>
                        - <strong>특징 추출기 (Feature Extractor):</strong> 모델의 앞부분으로, 입력 데이터(이미지 등)에서 선, 질감 같은 저수준 특징부터 눈, 코 같은 고수준 특징까지 자동으로 추출합니다.<br>
                        - <strong>분류기 (Classifier):</strong> 추출된 특징들을 바탕으로 최종적으로 데이터를 분류하거나 예측합니다.</p>
                    </div>
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">CNN의 이미지 인식 과정</h3>
                        <p>합성곱 신경망(CNN)은 이미지 인식에 탁월한 성능을 보이는 딥러닝 모델입니다. 인식 과정은 다음과 같은 흐름으로 이루어집니다.</p>
                        <div class="flex flex-col md:flex-row items-center justify-center space-y-4 md:space-y-0 md:space-x-4 text-center mt-4">
                            <div class="p-4 bg-slate-100 rounded-lg w-full md:w-auto"><strong>입력 이미지</strong></div>
                            <div class="text-2xl text-indigo-400 font-mono">&rarr;</div>
                            <div class="p-4 bg-indigo-100 rounded-lg w-full md:w-auto"><strong>합성곱(Conv) & 풀링(Pool)</strong><br><small>(특징 추출)</small></div>
                            <div class="text-2xl text-indigo-400 font-mono">&rarr;</div>
                            <div class="p-4 bg-indigo-100 rounded-lg w-full md:w-auto"><strong>... 반복 ...</strong></div>
                            <div class="text-2xl text-indigo-400 font-mono">&rarr;</div>
                            <div class="p-4 bg-teal-100 rounded-lg w-full md:w-auto"><strong>완전 연결 계층(FC)</strong><br><small>(분류)</small></div>
                            <div class="text-2xl text-indigo-400 font-mono">&rarr;</div>
                            <div class="p-4 bg-slate-100 rounded-lg w-full md:w-auto"><strong>출력 결과</strong></div>
                        </div>
                    </div>
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">컬러 이미지 처리와 드롭아웃</h3>
                        <p><strong>컬러 이미지 처리:</strong> 흑백 이미지는 채널 1개, 컬러(RGB) 이미지는 3개의 채널을 가집니다. CNN은 각 채널별로 특징을 추출한 뒤 결과를 종합하여 색상 정보까지 학습에 활용합니다.<br>
                        <strong>드롭아웃(Dropout):</strong> 학습 과정에서 일부 뉴런을 무작위로 비활성화하여 모델이 특정 뉴런에 과도하게 의존하는 것을 막는 기법입니다. 이를 통해 과적합을 방지하고 모델의 일반화 성능을 높입니다.</p>
                    </div>
                </div>
            `,
            techniques: `
                <h2 class="text-3xl font-bold mb-6 text-slate-900 border-b-2 border-indigo-200 pb-2">학습 기법과 함수</h2>
                <p class="mb-8 text-slate-600">모델을 효과적으로 학습시키기 위한 주요 기법들과 신경망의 핵심 요소인 활성화 함수에 대해 알아봅니다.</p>
                 <div class="space-y-8">
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">전이 학습 (Transfer Learning)</h3>
                        <p>이미 대규모 데이터로 학습된 모델(pre-trained model)을 가져와 새로운 문제 해결에 활용하는 기법입니다. 처음부터 모든 것을 학습시키는 대신, 기존 모델이 학습한 지식을 이전받기 때문에 적은 데이터와 자원으로도 빠르고 효과적으로 모델을 구축할 수 있습니다.</p>
                    </div>
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">퍼셉트론의 학습률 (Learning Rate)</h3>
                        <p>학습률은 모델이 학습 과정에서 틀린 부분을 얼마나 강하게 반영하여 가중치를 업데이트할지 결정하는 '학습 보폭'입니다. 가중치 업데이트는 일반적으로 다음과 같은 공식을 따릅니다.<br>
                        <code class="block text-center my-2 text-base">w(new) = w(old) + η * (target - output) * x</code>
                        <span class="block text-center text-sm text-slate-500">(w: 가중치, η: 학습률, target: 실제값, output: 예측값, x: 입력값)</span><br>
                        - <strong>너무 크면:</strong> 최적점을 지나쳐 버리며 학습이 불안정해집니다 (오버슈팅).<br>
                        - <strong>너무 작으면:</strong> 학습 속도가 매우 느리고, 최적이 아닌 지점에서 학습이 멈출 수 있습니다.</p>
                    </div>
                    <div>
                        <h3 class="text-2xl font-semibold mb-3 text-indigo-700">활성화 함수 (Activation Function)</h3>
                        <p>신경망에 비선형성을 부여하여 복잡한 패턴을 학습할 수 있게 만드는 핵심적인 함수입니다. 대표적인 함수들의 공식은 다음과 같습니다.<br>
                           <ul class="list-disc list-inside mt-2 space-y-1 bg-slate-50 p-4 rounded-md">
                               <li><strong>Sigmoid:</strong> <code>σ(x) = 1 / (1 + e⁻ˣ)</code> - 결과를 0과 1 사이로 압축합니다.</li>
                               <li><strong>Tanh:</strong> <code>tanh(x) = (eˣ - e⁻ˣ) / (eˣ + e⁻ˣ)</code> - 결과를 -1과 1 사이로 압축합니다.</li>
                               <li><strong>Identity:</strong> <code>f(x) = x</code> - 입력값을 그대로 출력합니다. (항등 함수)</li>
                           </ul>
                        </p>
                        <p class="mt-4">아래 차트에서 각 활성화 함수들의 형태를 시각적으로 비교해보세요.</p>
                        <div class="chart-container"><canvas id="activationFnChart"></canvas></div>
                    </div>
                </div>
            `,
        };

        const contentDisplay = document.getElementById('content-display');
        const navCards = document.querySelectorAll('.nav-card');
        let logicGateChartInstance = null;
        let activationFnChartInstance = null;
        
        const destroyCharts = () => {
            if (logicGateChartInstance) {
                logicGateChartInstance.destroy();
                logicGateChartInstance = null;
            }
            if (activationFnChartInstance) {
                activationFnChartInstance.destroy();
                activationFnChartInstance = null;
            }
        };

        navCards.forEach(card => {
            card.addEventListener('click', () => {
                const topic = card.dataset.topic;
                destroyCharts();
                contentDisplay.innerHTML = `<div class="content-fade-in">${contentData[topic]}</div>`;
                
                if (topic === 'perceptrons') {
                    initLogicGateChart();
                } else if (topic === 'techniques') {
                    initActivationFnChart();
                }

                contentDisplay.scrollIntoView({ behavior: 'smooth', block: 'start' });
            });
        });

        function initLogicGateChart() {
            const ctx = document.getElementById('logicGateChart').getContext('2d');
            logicGateChartInstance = new Chart(ctx, {
                type: 'scatter',
                data: {
                    datasets: []
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        x: { min: -0.5, max: 1.5, grid: { color: '#e2e8f0' } },
                        y: { min: -0.5, max: 1.5, grid: { color: '#e2e8f0' } }
                    },
                    plugins: {
                        legend: { display: true },
                        title: { display: true, text: '논리 게이트', font: { size: 16 } },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `(${context.raw.x}, ${context.raw.y}) -> ${context.dataset.label}`;
                                }
                            }
                        }
                    },
                    animation: {
                        duration: 500
                    }
                }
            });
            updateLogicChart('AND');
        }
        
        function updateLogicChart(gate) {
            if (!logicGateChartInstance) return;

            const dataPoints = {
                '0': [{x: 0, y: 0}],
                '1': [{x: 0, y: 1}, {x: 1, y: 0}, {x: 1, y: 1}]
            };

            const gateOutputs = {
                AND: { '0': [{x: 0, y: 0}, {x: 0, y: 1}, {x: 1, y: 0}], '1': [{x: 1, y: 1}] },
                OR: { '0': [{x: 0, y: 0}], '1': [{x: 0, y: 1}, {x: 1, y: 0}, {x: 1, y: 1}] },
                XOR: { '0': [{x: 0, y: 0}, {x: 1, y: 1}], '1': [{x: 0, y: 1}, {x: 1, y: 0}] }
            };

            logicGateChartInstance.data.datasets = [
                {
                    label: '출력: 0',
                    data: gateOutputs[gate]['0'],
                    backgroundColor: 'rgb(250, 140, 136)',
                    pointRadius: 8,
                    pointHoverRadius: 10
                },
                {
                    label: '출력: 1',
                    data: gateOutputs[gate]['1'],
                    backgroundColor: 'rgb(136, 178, 250)',
                    pointRadius: 8,
                    pointHoverRadius: 10
                }
            ];
            
            logicGateChartInstance.options.plugins.title.text = `${gate} 게이트`;
            
            if (logicGateChartInstance.options.plugins.annotation) {
                 delete logicGateChartInstance.options.plugins.annotation;
            }

            if (gate === 'AND' || gate === 'OR') {
                 const lineCoords = gate === 'AND' ? {x1: 1.5, y1: 0, x2: 0, y2: 1.5} : {x1: 0.5, y1: -0.5, x2: -0.5, y2: 0.5};
                 
                 // Drawing the line manually as annotation plugin isn't included by default
                 if (!logicGateChartInstance.options.plugins.annotation) {
                    logicGateChartInstance.options.plugins.customLine = {
                        line: {
                            x1: gate === 'AND' ? 1.5 : 0.5, y1: gate === 'AND' ? 0.2 : -0.2,
                            x2: gate === 'AND' ? 0.2 : -0.2, y2: gate === 'AND' ? 1.5 : 0.5,
                        }
                    }
                 }
            } else {
                 if (logicGateChartInstance.options.plugins.customLine) {
                     delete logicGateChartInstance.options.plugins.customLine;
                 }
            }
            
            logicGateChartInstance.update();
        }

        Chart.register({
            id: 'customLinePlugin',
            afterDraw: (chart) => {
                if (chart.options.plugins.customLine) {
                    const { ctx, chartArea: { top, right, bottom, left }, scales: { x, y } } = chart;
                    const line = chart.options.plugins.customLine.line;
                    ctx.save();
                    ctx.beginPath();
                    ctx.moveTo(x.getPixelForValue(line.x1), y.getPixelForValue(line.y1));
                    ctx.lineTo(x.getPixelForValue(line.x2), y.getPixelForValue(line.y2));
                    ctx.lineWidth = 2;
                    ctx.strokeStyle = 'rgba(75, 192, 192, 0.8)';
                    ctx.stroke();
                    ctx.restore();
                }
            }
        });

        function initActivationFnChart() {
            const ctx = document.getElementById('activationFnChart').getContext('2d');
            const labels = Array.from({length: 11}, (_, i) => i - 5);
            const sigmoid = x => 1 / (1 + Math.exp(-x));
            const tanh = x => Math.tanh(x);
            const identity = x => x;
            
            activationFnChartInstance = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: labels,
                    datasets: [
                        {
                            label: 'Sigmoid',
                            data: labels.map(sigmoid),
                            borderColor: 'rgb(239, 68, 68)',
                            tension: 0.1,
                            borderWidth: 2
                        },
                        {
                            label: 'Tanh',
                            data: labels.map(tanh),
                            borderColor: 'rgb(59, 130, 246)',
                            tension: 0.1,
                             borderWidth: 2
                        },
                        {
                            label: 'Identity',
                            data: labels.map(identity),
                            borderColor: 'rgb(16, 185, 129)',
                            tension: 0.1,
                             borderWidth: 2
                        }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            grid: { color: '#e2e8f0' }
                        },
                        x: {
                            grid: { color: '#e2e8f0' }
                        }
                    },
                    plugins: {
                        title: { display: true, text: '주요 활성화 함수 비교', font: { size: 16 } }
                    }
                }
            });
        }
    </script>
</body>
</html>

